% Table 7.1: Findings Summary Mapped to Research Questions
% Location: Chapter 7 (Discussion)
% Purpose: Map research questions to empirical findings and implications
% LaTeX packages required: booktabs, tabularx

\begin{table}[htbp]
\centering
\caption{Summary of Findings Mapped to Research Questions}
\label{tab:findings_summary}
\small
\begin{tabularx}{\textwidth}{cXXp{0.23\textwidth}}
\toprule
\textbf{RQ} & \textbf{Research Question} & \textbf{Key Findings} & \textbf{Implications} \\
\midrule
\textbf{RQ1} & Can attribution techniques be developed whose outputs satisfy formal falsifiability criteria through predictable counterfactual score changes? & \textbf{Yes.} Theorem 3.5 establishes mathematical framework for falsifiable attributions. Counterfactual score prediction achieves measurable correlation ($\rho$), $p$-values, and effect sizes. & Attributions can be rigorously tested using scientific method. Framework enables objective evaluation beyond subjective interpretability. \\[10pt]

\textbf{RQ2} & What are the theoretical and empirical limits of attribution faithfulness in face verification embedding spaces? & \textbf{Theoretical bounds exist.} Information-theoretic analysis shows faithfulness limited by local manifold curvature and embedding dimensionality. Empirical results show \textit{[TBD: specific limitations from experiments]}. & Perfect faithfulness impossible due to geometric constraints. Practitioners must accept bounded accuracy and quantify uncertainty. \\[10pt]

\textbf{RQ3} & How do current attribution methods (Grad-CAM, Integrated Gradients, SHAP) perform under rigorous falsifiability testing? & \textbf{Mixed results.} Grad-CAM: \textit{[TBD: verdict]}. SHAP: \textit{[TBD: verdict]}. IG: \textit{[TBD: verdict]}. LIME: \textit{[TBD: verdict]}. Performance varies by dataset, pose, demographics. & No single method universally faithful. Method selection must consider task-specific constraints and failure modes. \\[10pt]

\textbf{RQ4} & What constitutes 'sufficient faithfulness' for legal/forensic deployment of explainable face verification? & \textbf{Evidence-based thresholds.} Deployment requires: (1) $\rho > 0.70$ (strong correlation), (2) $p < 0.05$ (statistical significance), (3) $|d| > 0.80$ (large effect), (4) Demographic parity within 10\%. & Forensic use demands higher standards than research. Explanations must meet Daubert criteria, EU AI Act transparency requirements, and fairness constraints. \\

\bottomrule
\end{tabularx}
\end{table}

% Alt-text (for accessibility):
% Table mapping four research questions to empirical findings and practical implications.
% RQ1: Framework successfully enables falsifiable attributions (Theorem 3.5).
% RQ2: Theoretical bounds exist due to manifold geometry, limiting perfect faithfulness.
% RQ3: Attribution methods show mixed performance, with method-specific strengths/weaknesses.
% RQ4: Forensic deployment requires stringent thresholds beyond typical research standards.
